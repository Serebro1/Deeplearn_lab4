{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastai.data.external import untar_data, URLs\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем датасет CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "batch_size = 100\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size * 2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "trainloader = DeviceDataLoader(trainloader, device)\n",
    "testloader = DeviceDataLoader(testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels)  \n",
    "        return loss,acc\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, last_lr: {:.5f}\".format(\n",
    "            epoch+1, result['train_loss'], result['train_accuracy'], result['val_loss'], result['val_acc'], result['lrs'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим 4 встроенные модели библиотеки pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Otche/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\Otche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Otche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AlexNet                                  [400, 1000]               --\n",
       "├─Sequential: 1-1                        [400, 256, 6, 6]          --\n",
       "│    └─Conv2d: 2-1                       [400, 64, 56, 56]         23,296\n",
       "│    └─ReLU: 2-2                         [400, 64, 56, 56]         --\n",
       "│    └─MaxPool2d: 2-3                    [400, 64, 27, 27]         --\n",
       "│    └─Conv2d: 2-4                       [400, 192, 27, 27]        307,392\n",
       "│    └─ReLU: 2-5                         [400, 192, 27, 27]        --\n",
       "│    └─MaxPool2d: 2-6                    [400, 192, 13, 13]        --\n",
       "│    └─Conv2d: 2-7                       [400, 384, 13, 13]        663,936\n",
       "│    └─ReLU: 2-8                         [400, 384, 13, 13]        --\n",
       "│    └─Conv2d: 2-9                       [400, 256, 13, 13]        884,992\n",
       "│    └─ReLU: 2-10                        [400, 256, 13, 13]        --\n",
       "│    └─Conv2d: 2-11                      [400, 256, 13, 13]        590,080\n",
       "│    └─ReLU: 2-12                        [400, 256, 13, 13]        --\n",
       "│    └─MaxPool2d: 2-13                   [400, 256, 6, 6]          --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [400, 256, 6, 6]          --\n",
       "├─Sequential: 1-3                        [400, 1000]               --\n",
       "│    └─Dropout: 2-14                     [400, 9216]               --\n",
       "│    └─Linear: 2-15                      [400, 4096]               37,752,832\n",
       "│    └─ReLU: 2-16                        [400, 4096]               --\n",
       "│    └─Dropout: 2-17                     [400, 4096]               --\n",
       "│    └─Linear: 2-18                      [400, 4096]               16,781,312\n",
       "│    └─ReLU: 2-19                        [400, 4096]               --\n",
       "│    └─Linear: 2-20                      [400, 1000]               4,097,000\n",
       "==========================================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 61,100,840\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 286.91\n",
       "==========================================================================================\n",
       "Input size (MB): 247.34\n",
       "Forward/backward pass size (MB): 1604.12\n",
       "Params size (MB): 244.40\n",
       "Estimated Total Size (MB): 2095.86\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alexNet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexNet.eval()\n",
    "\n",
    "resNet34 = torchvision.models.resnet34()\n",
    "resNet34.eval()\n",
    "\n",
    "resNext50 = torchvision.models.resnext50_32x4d()\n",
    "resNext50.eval()\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(alexNet, input_size=(batch_size, 3, 227, 227))\n",
    "# summary(resNet34, input_size=(batch_size, 3, 227, 227))\n",
    "# summary(resNext50, input_size=(batch_size, 3, 227, 227))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
